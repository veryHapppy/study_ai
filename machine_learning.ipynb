{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHRwSfq43rfrZkMx0TCYMz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veryHapppy/study_ai/blob/main/machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install optuna\n",
        "#!pip install catboost\n",
        "#!pip install category_encoders\n",
        "from urllib.request import urlopen\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import joblib\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import VotingRegressor, StackingRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "import shap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw0dei_YMBPT",
        "outputId": "e4560f24-3cd7-4eff-a0da-1bcdf8701d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "tY8_K6TJ4KA_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXjmTmGQ35zE"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing : 데이터 전처리\n",
        "# Garbage In, Garbage Out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#titanic data 저장하기\n",
        "with open(\"titanic.csv\", \"w\", encoding=\"UTF8\") as f:\n",
        "    resp = urlopen('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
        "    f.write(resp.read().decode('utf-8'))"
      ],
      "metadata": {
        "id": "UtqYTsmw40k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.결측치 처리 (Missing Value)\n",
        "data = pd.read_csv(\"titanic.csv\")\n",
        "print(data.isnull().sum()) # 컬럼별로 빈 값 개수 확인\n",
        "\n",
        "#data = data.dropna(subset=['Cabin']) # 비어있는 행 삭제\n",
        "data['Age'] = data['Age'].fillna(data['Age'].median()) # 중앙값으로 대체\n",
        "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0]) #최빈값으로 대체\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6CjThLVa4Wxc",
        "outputId": "f6511064-83e3-4dd1-f5a2-3d85c44829fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 이상치 처리\n",
        "# 박스 플롯을 그려서 이상치 확인\n",
        "# 보통 기준을 Q3-Q1의 1.5배로 설정, 상한선과 하한선을 둠\n",
        "Q1 = data['Fare'].quantile(0.25)\n",
        "Q3 = data['Fare'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "upper_limit = Q3 + IQR * 1.5\n",
        "\n",
        "data['Fare'] = np.where(data['Fare'] > upper_limit, upper_limit, data['Fare']) # 상한선을 넘는 값은 상한선 값으로 조정\n"
      ],
      "metadata": {
        "id": "NLmH24pR6qo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 피처 엔지니어링\n",
        "# 기존 데이터로 학습하기 좋은 데이터를 만듦\n",
        "# titanic의 SibSp(형제, 배우자 수)와 Parch(부모, 자녀 수)를 합쳐 FamilySize를 만듦\n",
        "data['FamilySize'] = data['SibSp'] + data['Parch'] + 1"
      ],
      "metadata": {
        "id": "MzYPOQto8nNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 인코딩\n",
        "# 글자를 숫자로 바꿈\n",
        "# 레이블 인코딩 : 카테고리별로 고유한 숫자 부여 - 모델이 숫자 값을 의미있게 받아들일 수도 있음\n",
        "# 원-핫 인코딩 : 각 카테고리를 새로운 열로 만들고 해당하는 카테고리인 경우만 1, 아니면 0\n",
        "#                항목이 많아지면 컬럼 수가 급격히 증가\n",
        "# sex의 male, female을 숫자로 변경\n",
        "\n",
        "# 레이블 인코딩 / 알파벳 순서로 정수로 변환\n",
        "le = LabelEncoder()\n",
        "data['Sex'] = le.fit_transform(data['Sex'])\n",
        "\n",
        "# 원-핫 인코딩 / embarked_C, embarked_Q, embarked_S 생성\n",
        "data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)\n",
        "# drop_first : 첫번째 생성되는 열을 없앰 -> 선형 모델에서는 필요 (다중공선성 방지)"
      ],
      "metadata": {
        "id": "DTmoLlvT88Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 스케일링\n",
        "# 숫자 범위를 일정한 기준으로 맞추는 작업\n",
        "# 모델이 숫자가 전체적으로 큰 컬럼을 중요한 데이터로 착각할 수 있음\n",
        "\n",
        "# 표준화 (Standardization) : 0 ~ 1, 분포모양 유지\n",
        "std_scaler = StandardScaler()\n",
        "data['Age_std'] = std_scaler.fit_transform(data[['Age']])\n",
        "\n",
        "# 정규화 (Normalization) : 평균 0, 표준편차 1\n",
        "# 이상치가 많을 때 안정적\n",
        "mm_scaler = MinMaxScaler()\n",
        "data['Fare_minmax'] = mm_scaler.fit_transform(data[['Fare']])"
      ],
      "metadata": {
        "id": "uMIYnlEI88XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 결과 확인\n",
        "columns_to_drop = ['PassengerId','Pclass','Name', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Age','Fare']\n",
        "data_final = data.drop(columns=columns_to_drop)\n",
        "\n",
        "print(\"--- 전처리 완료된 데이터\")\n",
        "print(data_final.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwfagmFOBtQx",
        "outputId": "6f7f5e18-d349-4684-e616-60e01e45118d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 전처리 완료된 데이터\n",
            "   Survived  Sex  FamilySize  Embarked_Q  Embarked_S   Age_std  Fare_minmax\n",
            "0         0    1           2       False        True -0.565736     0.110460\n",
            "1         1    0           2       False       False  0.663861     1.000000\n",
            "2         1    0           1       False        True -0.258337     0.120745\n",
            "3         1    0           2       False        True  0.433312     0.809027\n",
            "4         0    1           1       False        True  0.433312     0.122649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 고급 기법"
      ],
      "metadata": {
        "id": "8lAWrlm4JkSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 차원 축소 (Dimension Reduction)\n",
        "# PCA : 주성분 분석, 여러 변수의 특징을 추출하여 중요한 몇개의 변수로 합치는 기술\n",
        "# 적용 전에 스케일링 필수\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data[['Age', 'Fare', 'FamilySize']]) # 스케일링\n",
        "\n",
        "pca = PCA(n_components=2) # 주성분 개수, n_components에 보존하고 싶은 정보량의 비율을 넣을 수 있음\n",
        "data_pca = pca.fit_transform(data_scaled)\n",
        "pca_df = pd.DataFrame(data=data_pca, columns=['PC1', 'PC2'])\n",
        "\n",
        "# 원본 데이터의 정보 설명력 확인, 보통 각 행의 비율을 더했을 때 70~90% 이상이면 OK\n",
        "# 시각화가 목적이면 2 or 3개로 고정\n",
        "print(pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmVWaWv5JpNZ",
        "outputId": "538a8f87-6ad3-4f7b-c673-3342034a9af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.46358827 0.37663531]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install imbalanced-learn"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OH5PkI4iKoSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 불균형 데이터 처리\n",
        "# 특정 클래스의 데이터가 다른 클래스에 비해 압도적으로 많거나 적을때 진행\n",
        "# 언더샘플링 / 오버샘플링 : SMOTE(소수 데이터의 특징으로 가상의 데이터를 만들어냄)\n",
        "\n",
        "# x : Feature, 모델이 학습할 데이터\n",
        "# y : Target, 정답 데이터\n",
        "x = data_final.drop('Survived', axis=1)\n",
        "y = data_final['Survived']\n",
        "\n",
        "#random_state : 랜덤 결과를 일정하게 함, 0 ~ 100이면 상관X\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# 생존자, 사망자의 데이터 개수를 맞춤 (소수 데이터를 만들어냄)\n",
        "x_resampled, y_resampled = smote.fit_resample(x, y)\n",
        "\n",
        "print(f\"변환 전 정답 분포:\\n{y.value_counts()}\")\n",
        "print(f\"변환 후 정답 분포:\\n{y_resampled.value_counts()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ESypogKXKoP1",
        "outputId": "fc129962-6028-403b-d451-36a91ee86461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "변환 전 정답 분포:\n",
            "Survived\n",
            "0    549\n",
            "1    342\n",
            "Name: count, dtype: int64\n",
            "변환 후 정답 분포:\n",
            "Survived\n",
            "0    549\n",
            "1    549\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습"
      ],
      "metadata": {
        "id": "YamNPk1DSLqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 나누기\n",
        "\n",
        "# 8:2로 분리 (데이터가 만개가 넘으면 10%만 써도 괜찮음)\n",
        "# stratify=y_resampled : 정답 데이터의 비율을 유지\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
        ")"
      ],
      "metadata": {
        "id": "kUavujNnSUwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성 (결정트리 모델 사용)\n",
        "#model = DecisionTreeClassifier(random_state=42)\n",
        "# 랜덤 포레스트 모델 : 결정트리를 여러개 사용(100개)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "HmADlYLIT-2-",
        "outputId": "6bd18ec3-58ae-4729-d814-0fbfe75cd83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가\n",
        "\n",
        "# 예측하기\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# 채점\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"모델의 예측 정확도: {(accuracy * 100):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luyotO87UHgd",
        "outputId": "dc083f32-40ae-43f1-e745-fd8e55e57844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 예측 정확도: 85.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중요한 컬럼 시각화\n",
        "\n",
        "importances = model.feature_importances_\n",
        "feature_names = x.columns\n",
        "\n",
        "# 가로 10인치, 세로 6인치 그래프 창 생성\n",
        "plt.figure(figsize=(10, 6))\n",
        "indices = np.argsort(importances)\n",
        "# 가로 막대그래프 생성\n",
        "plt.barh(range(len(indices)), importances[indices], align='center')\n",
        "# y축 눈금에 컬럼 이름 작\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('What influenced the survival the most?')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "collapsed": true,
        "id": "3bDit3RUVaTN",
        "outputId": "0c7fe48e-26ce-426c-eeed-64f58380dbec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GridSearchCV"
      ],
      "metadata": {
        "id": "RFfPYOcOYPW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터\n",
        "# 모델의 설정값을 최적으로 맞추는 과정\n",
        "# 설정값의 후보를 던져주면 테스트 후 가장 좋은 모델 사용\n",
        "\n",
        "# n_estimators : 랜덤 포레스트에서 결정 트리 개수\n",
        "# max_depth : 최대 깊이 (너무 깊으면 과적합 발생)\n",
        "# min_samples_split : 노드를 분할하기 위한 최소한의 데이터 수 (노드가 너무 많아 지는 것을 방지)\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# cv : train 데이터를 5등분해서 하나를 테스트로 사용, 5번 반복 (8:2 비율 유지)\n",
        "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
        "\n",
        "#test 데이터 없이도 내부적으로 성능 측정 가능\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "print(f\"최적의 설정값: {grid_search.best_params_}\")\n",
        "print(f\"최고 정확도: {grid_search.best_score_:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLVE2aT2XiCu",
        "outputId": "f7597ab4-06d8-415e-9b75-914240c43d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 설정값: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 25}\n",
            "최고 정확도: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *pipeline"
      ],
      "metadata": {
        "id": "ND27iftkzLCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TitleExtractor(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        # 정규표현식으로 호칭 추출\n",
        "        X['Title'] = X['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "        # 호칭 단순화\n",
        "        rare_titles = ['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
        "        X['Title'] = X['Title'].replace(rare_titles, 'Rare')\n",
        "        X['Title'] = X['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
        "        X['Title'] = X['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "        # 'Name' 컬럼은 이제 필요 없으므로 삭제 (Title 컬럼만 남김)\n",
        "        return X.drop(['Name'], axis=1)\n",
        "\n",
        "# 1. 데이터 로드 및 기본 정리\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "# 학습에 사용할 핵심 특성만 선택\n",
        "features = ['Name', 'Age', 'Fare', 'Embarked', 'Sex', 'Pclass']\n",
        "X = df[features]\n",
        "y = df['Survived']\n",
        "\n",
        "# 데이터 분할 (8:2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. 수치형 데이터 전처리 공정 (나이, 요금, 객실등급)\n",
        "num_features = ['Age', 'Fare', 'Pclass']\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')), # 빈칸은 중앙값으로\n",
        "    ('scaler', StandardScaler())                   # 표준화 스케일링\n",
        "])\n",
        "\n",
        "# 3. 범주형 데이터 전처리 공정 (항구, 성별)\n",
        "cat_features = ['Embarked', 'Sex', 'Title']\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')), # 빈칸은 최빈값으로\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop=None))    # 원-핫 인코딩\n",
        "])\n",
        "\n",
        "# 4. 전처리 도구 통합 (ColumnTransformer)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', num_transformer, num_features),\n",
        "        ('cat', cat_transformer, cat_features)\n",
        "    ])\n",
        "\n",
        "# 5. 전체 파이프라인 구축 (전처리 + 모델)\n",
        "full_pipeline = Pipeline(steps=[\n",
        "    ('title_ext', TitleExtractor()), # 1단계: 이름에서 호칭 뽑기\n",
        "    ('preprocessor', preprocessor),   # 2단계: 나머지 수치/범주형 전처리\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# 6. 학습 시작 (원본 데이터를 그대로 넣음)\n",
        "full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. 성능 확인\n",
        "score = full_pipeline.score(X_test, y_test)\n",
        "print(f\"테스트 데이터 정확도: {score:.4f}\")\n",
        "\n",
        "# 8. 파이프라인 전체 저장\n",
        "joblib.dump(full_pipeline, 'titanic_model_pipeline.pkl')\n",
        "print(\"파이프라인 저장 완료\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "ZcKXGM6MzM5-",
        "outputId": "de08f825-a377-448a-f6fa-7b61f97d31dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-946049864.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# 1. 데이터 로드 및 기본 정리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# 학습에 사용할 핵심 특성만 선택\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Optuna"
      ],
      "metadata": {
        "id": "_-ZE80seeDYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optuna : 테스트를 바탕으로 모델이 알아서 설정값을 바꿈\n",
        "# objective 함수 : 어떤 모델, 어떤 다이얼을 돌릴지 정의\n",
        "# trial : 한번의 시도\n",
        "# study : 최적화 과정 전체\n",
        "#!pip install optuna\n",
        "\n",
        "def objective(trial):\n",
        "    # 1. 시도해볼 다이얼 범위 지정 (trial.suggest_...)\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
        "        'verbose': -1\n",
        "    }\n",
        "\n",
        "    # 2. 모델 설정\n",
        "    model = LGBMClassifier(**params, random_state=42)\n",
        "\n",
        "    # 3. 교차 검증 점수를 계산 (이 점수가 높아야 함)\n",
        "    # 파이프라인 안에 넣어 사용하면 전처리까지 포함됩니다.\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('m', model)])\n",
        "    score = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
        "\n",
        "    return score\n",
        "\n",
        "# 4. 최적화 실행\n",
        "study = optuna.create_study(direction='maximize') # 점수를 최대화하는 방향으로\n",
        "study.optimize(objective, n_trials=50) # 50번 시도\n",
        "\n",
        "print(f\"최고 점수: {study.best_value:.4f}\")\n",
        "print(f\"최적 파라미터: {study.best_params}\")"
      ],
      "metadata": {
        "id": "wf5I2MwZYkyF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "collapsed": true,
        "outputId": "aae8d1d9-c4aa-4dc7-8643-617da9055182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-22 10:26:16,588] A new study created in memory with name: no-name-88122437-3973-47b8-b881-adeef04e2ded\n",
            "[W 2025-12-22 10:26:16,595] Trial 0 failed with parameters: {'n_estimators': 284, 'max_depth': 8, 'learning_rate': 0.04970365298053341, 'num_leaves': 48, 'min_child_samples': 29} because of the following error: NameError(\"name 'preprocessor' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1701107397.py\", line 23, in objective\n",
            "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('m', model)])\n",
            "                                                ^^^^^^^^^^^^\n",
            "NameError: name 'preprocessor' is not defined\n",
            "[W 2025-12-22 10:26:16,605] Trial 0 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'preprocessor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1701107397.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# 4. 최적화 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 점수를 최대화하는 방향으로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 50번 시도\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"최고 점수: {study.best_value:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mfrozen_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     ):\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1701107397.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# 3. 교차 검증 점수를 계산 (이 점수가 높아야 함)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# 파이프라인 안에 넣어 사용하면 전처리까지 포함됩니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocessor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 튜닝 (하이퍼파라미터)\n",
        "# 별명__설정값 이름\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__n_estimators' : [100, 200, 300],\n",
        "    'classifier__max_depth' : [None, 5, 10, 20],\n",
        "    'classifier__min_samples_split' : [2, 5, 10],\n",
        "    'preprocessor__num__imputer__strategy': ['mean', 'median'] # 전처리 과정의 설정도 변경 가능\n",
        "}\n",
        "\n",
        "# 학습 n_jobs : 병렬로 사용할 CPU 수, verbose : 학습 중 보고 방식(숫자가 클수록 자주 보고함)\n",
        "grid_search = GridSearchCV(full_pipeline, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 결과\n",
        "print(f\"최적의 파라미터: {grid_search.best_params_}\")\n",
        "print(f\"최고 정확도: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# 최종 테스트\n",
        "final_score = best_model.score(X_test, y_test)\n",
        "print(f\"최종 실전 정확도: {final_score:.4f}\")\n",
        "\n",
        "# 저장\n",
        "joblib.dump(best_model, 'titanic_best_pipeline.pkl')"
      ],
      "metadata": {
        "id": "ibMQI_kezP0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load"
      ],
      "metadata": {
        "id": "2cdKk8_PzR_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# 저장된 파일 불러오기\n",
        "loaded_model = joblib.load('titanic_best_pipeline.pkl')\n",
        "\n",
        "new_passenger = pd.DataFrame({\n",
        "    'age': [25],\n",
        "    'fare': [50.0],\n",
        "    'embarked': ['S'],\n",
        "    'sex': ['female'],\n",
        "    'pclass': [1]\n",
        "})\n",
        "\n",
        "prediction = loaded_model.predict(new_passenger)\n",
        "probability = loaded_model.predict_proba(new_passenger)\n",
        "print(probability)\n",
        "\n",
        "# 3. 결과 출력\n",
        "print(\"-\" * 30)\n",
        "if prediction[0] == 1:\n",
        "    print(f\"예측 결과: [ 생존 ]\")\n",
        "    print(f\"생존 확률: {probability[0][1]*100:.2f}%\")\n",
        "else:\n",
        "    print(f\"예측 결과: [ 사망 ]\")\n",
        "    print(f\"사망 확률: {probability[0][0]*100:.2f}%\")\n",
        "print(\"-\" * 30)\n"
      ],
      "metadata": {
        "id": "VjlQrhbWzStO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ensemble"
      ],
      "metadata": {
        "id": "KNA78NYu2jnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앙상블 만드는 과정\n",
        "1. 개별 모델 튜닝 : 각각의 모델에 대해 최적의 파라미터를 찾음\n",
        "2. 가중치 부여 : 모델의 실력에 따라 가중치 부여\n",
        "3. VotingClassifier, StackingClassifier로 묶음"
      ],
      "metadata": {
        "id": "SYqhB2gM8YuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 앙상블 구현 (XGBoost, LightGBM)\n",
        "\n",
        "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "lgbm_model = LGBMClassifier(n_estimators=100,   # 결정 트리의 개수 (많으면 과적합, 적으면 성능이 안나옴)\n",
        "                            learning_rate=0.05, # 이전 트리의 오차를 반영하는 학습률 (0.01~0.1)\n",
        "                                                # 보통 n_esitimators와 반비례로 밸런스 조절\n",
        "                            num_leaves=31,      # 트리 하나가 가질 수 있는 leaf node의 개수 (<2^(max_depth))\n",
        "                            random_state=42,\n",
        "                            verbose=-1\n",
        "                            )\n",
        "\n",
        "voting_model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_model),\n",
        "        ('lgbm', lgbm_model)\n",
        "    ],\n",
        "    #weights=[2,1] # XGBoost에 두배의 가중치 제공\n",
        "    voting='soft') # soft : 확률을 평균내서 결정, hard : 다수결로 결정\n",
        "\n",
        "# 파이프라인 구축\n",
        "ensemble = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('voting_model', voting_model)\n",
        "])\n",
        "\n",
        "# 학습\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# 평가\n",
        "print(f\"{ensemble.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# 저장\n",
        "joblib.dump(ensemble, 'titanic_ensemble.pkl')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BF_AtJHe2wT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# + CatBoost"
      ],
      "metadata": {
        "id": "R3yBAgNZ6YZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CatBoost : 범주형 변수를 처리하는데 특화 (성별, 직업, 혈액형 등)\n",
        "# 문자열을 넣어도 내부적으로 숫자로 변환\n",
        "# 결정 트리를 만들 때 왼쪽과 오른쪽 자식 노드를 항상 같은 조건으로 분할 (대칭 트리)\n",
        "# 튜닝할 시간이 없을 때처럼 기본값 성능이 가장 좋음\n",
        "# !pip install catboost\n",
        "\n",
        "cat_model = CatBoostClassifier(\n",
        "    iterations=500,        # == n_estimators\n",
        "    learning_rate=0.05,    # 학습률\n",
        "    depth=6,               # 트리 깊이\n",
        "    random_seed=42,\n",
        "    verbose=0              # 중간 학습 과정 생략\n",
        ")\n",
        "\n",
        "voting_model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_model),\n",
        "        ('lgbm', lgbm_model),\n",
        "        ('cat', cat_model)\n",
        "    ],\n",
        "    voting='soft')\n",
        "\n",
        "# 파이프라인 구축\n",
        "ensemble = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('voting_model', voting_model)\n",
        "])\n",
        "\n",
        "# 학습\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# 평가\n",
        "print(f\"{ensemble.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# 저장\n",
        "joblib.dump(ensemble, 'titanic_three_model_ensemble.pkl')"
      ],
      "metadata": {
        "id": "3go04peh6eUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacking"
      ],
      "metadata": {
        "id": "jXnZ8mBUEY20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stacking : 모델들의 예측값을 입력 데이터로 사용 -> 메타 모델이 최종 결정을 내림\n",
        "# 메타 모델이 복잡하면 과적합 확률이 매우 커짐, 단순한 로지스틱 회귀 모델을 주로 사\n",
        "\n",
        "\n",
        "base_model = [\n",
        "        ('xgb', xgb_model),\n",
        "        ('lgbm', lgbm_model),\n",
        "        ('cat', cat_model)\n",
        "]\n",
        "\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators = base_model,\n",
        "    final_estimator = LogisticRegression(),\n",
        "    cv = 5\n",
        ")\n",
        "\n",
        "\n",
        "stacking_ensemble = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('stacking_model', stacking_model)\n",
        "])\n",
        "\n",
        "stacking_ensemble.fit(X_train, y_train)\n",
        "\n",
        "final_score = stacking_ensemble.score(X_test, y_test)\n",
        "print(f\"최종 실전 정확도: {final_score:.4f}\")\n",
        "\n",
        "# 저장\n",
        "joblib.dump(best_model, 'titanic_best_pipeline.pkl')"
      ],
      "metadata": {
        "id": "vF51mrab8Xrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Optuna + (voting, stacking)"
      ],
      "metadata": {
        "id": "DYtNooegheQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # 1. 각 모델별 다이얼 범위 설정\n",
        "    # XGBoost 파라미터\n",
        "    xgb_params = {\n",
        "        'n_estimators': trial.suggest_int('xgb_n', 50, 200),\n",
        "        'max_depth': trial.suggest_int('xgb_depth', 3, 7),\n",
        "        'colsample_bytree': trial.suggest_float('xgb_colsample', 0.6, 0.8),\n",
        "        'reg_alpha': trial.suggest_float('xgb_alpha', 1e-3, 10.0, log=True),\n",
        "        'reg_lambda': trial.suggest_float('xgb_lambda', 1e-3, 10.0, log=True),\n",
        "        'learning_rate': trial.suggest_float('xgb_lr', 0.01, 0.1),\n",
        "    }\n",
        "\n",
        "    # LightGBM 파라미터\n",
        "    lgbm_params = {\n",
        "        'n_estimators': trial.suggest_int('lgbm_n', 50, 200),\n",
        "        'num_leaves': trial.suggest_int('lgbm_leaves', 15, 50),\n",
        "        'learning_rate': trial.suggest_float('lgbm_lr', 0.01, 0.1),\n",
        "        'verbose': -1\n",
        "    }\n",
        "\n",
        "    # CatBoost 파라미터\n",
        "    cat_params = {\n",
        "        'iterations': trial.suggest_int('cat_iter', 50, 200),\n",
        "        'depth': trial.suggest_int('cat_depth', 3, 7),\n",
        "        'learning_rate': trial.suggest_float('cat_lr', 0.01, 0.1),\n",
        "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
        "        'random_strength': trial.suggest_float('random_strength', 0.1, 10.0),\n",
        "        'verbose': 0\n",
        "    }\n",
        "\n",
        "    # 2. 모델간 가중치(Weight) 설정\n",
        "    w_xgb = trial.suggest_float('w_xgb', 0.5, 2.0) # 0.5~2.0 사이의 실수\n",
        "    w_lgbm = trial.suggest_float('w_lgbm', 0.5, 2.0)\n",
        "    w_cat = trial.suggest_float('w_cat', 0.5, 2.0)\n",
        "\n",
        "    # 3. 모델 객체 생성\n",
        "    xgb = XGBClassifier(**xgb_params, random_state=42)\n",
        "    lgbm = LGBMClassifier(**lgbm_params, random_state=42)\n",
        "    cat = CatBoostClassifier(**cat_params, random_state=42)\n",
        "\n",
        "    # 4. 앙상블 모델 구축\n",
        "    voting_model = VotingClassifier(\n",
        "        estimators=[('xgb', xgb), ('lgbm', lgbm), ('cat', cat)],\n",
        "        voting='soft',\n",
        "        weights=[w_xgb, w_lgbm, w_cat]\n",
        "    )\n",
        "\n",
        "    # 5. 파이프라인 연결 및 평가\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('title_ext', TitleExtractor()),\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('ensemble', voting_model)\n",
        "    ])\n",
        "\n",
        "    # 교차 검증으로 점수 측정 (과적합 방지를 위해 5-Fold 사용)\n",
        "    score = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
        "\n",
        "    return score\n",
        "\n",
        "# 6. 최적화 실행\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=70) # 시도 횟수\n",
        "\n",
        "print(f\"최고 정확도: {study.best_value:.4f}\")\n",
        "for i in study.best_params:\n",
        "    print(f\"{i}: {study.best_params[i]}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z8EragK5hk-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best = study.best_params\n",
        "\n",
        "xgb_final = XGBClassifier(\n",
        "    n_estimators=best['xgb_n'],\n",
        "    max_depth=best['xgb_depth'],\n",
        "    learning_rate=best['xgb_lr'],\n",
        "    colsample_bytree=best['xgb_colsample'],\n",
        "    reg_alpha=best['xgb_alpha'],\n",
        "    reg_lambda=best['xgb_lambda'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgbm_final = LGBMClassifier(\n",
        "    n_estimators=best['lgbm_n'],\n",
        "    num_leaves=best['lgbm_leaves'],\n",
        "    learning_rate=best['lgbm_lr'],\n",
        "    random_state=42,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "cat_final = CatBoostClassifier(\n",
        "    iterations=best['cat_iter'],\n",
        "    depth=best['cat_depth'],\n",
        "    learning_rate=best['cat_lr'],\n",
        "    l2_leaf_reg=best['l2_leaf_reg'],\n",
        "    random_strength=best['random_strength'],\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# voting 방식\n",
        "voting_model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_final),\n",
        "        ('lgbm', lgbm_final),\n",
        "        ('cat', cat_final)\n",
        "    ],\n",
        "    voting='soft',\n",
        "    weights=[best['w_xgb'], best['w_lgbm'], best['w_cat']]\n",
        ")\n",
        "\n",
        "#stacking 방식\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_final),\n",
        "        ('lgbm', lgbm_final),\n",
        "        ('cat', cat_final)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "final_voting_pipeline = Pipeline(steps=[\n",
        "    ('title_ext', TitleExtractor()),\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', voting_model)\n",
        "])\n",
        "final_stacking_pipeline = Pipeline(steps=[\n",
        "    ('title_ext', TitleExtractor()),\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', stacking_model)\n",
        "])\n",
        "\n",
        "final_voting_pipeline.fit(X_train, y_train)\n",
        "final_stacking_pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(f\"voting 검증 점수: {final_voting_pipeline.score(X_test, y_test):.4f}\")\n",
        "print(f\"stacking 검증 점수: {final_stacking_pipeline.score(X_test, y_test):.4f}\")\n",
        "\n",
        "# 6. 모델 저장\n",
        "joblib.dump(final_voting_pipeline, 'titanic_voting_best.pkl')\n",
        "joblib.dump(final_stacking_pipeline, 'titanic_stacking_best.pkl')\n",
        "print(\"저장되었습니다\")\n"
      ],
      "metadata": {
        "id": "-uh13aKih00B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정확도 높이기"
      ],
      "metadata": {
        "id": "puXiUuyprOKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Target Encoding\n",
        "# 범주형 변수의 각각의 범주를 타겟값 평균으로 변환\n",
        "# 원핫 인코딩의 변수가 늘어나는 단점을 해결\n",
        "# smoothing = (해당 그룹의 데이터 수 * 그룹 평균 + 스무딩 계수 * 전체 평균)  /  (해당 그룹의 데이터 수 + 스무딩 계수)\n",
        "# -> 데이터가 적은 범주는 전체 평균에 가깝게 변환\n",
        "\n",
        "# 일반적인 학습\n",
        "encoder = TargetEncoder(cols=['HomePlanet', 'Deck'])\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "\n",
        "# pipeline\n",
        "Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    # 'onehot' 대신 'target'\n",
        "    ('target', TargetEncoder(smoothing=10))\n",
        "])\n",
        "\n",
        "# Optuna\n",
        "smoothing = trial.suggest_int('smoothing', 5, 50)\n",
        "encoder = TargetEncoder(cols=cat_features, smoothing=smoothing)"
      ],
      "metadata": {
        "id": "6zt3tJKlrPfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature interaction\n",
        "# 단순히 여러 변수를 모델에 넘겨주는게 아닌\n",
        "# 변수들의 관계를 이용해 새로운 변수를 생성\n",
        "# 더 좋은 정보력을 가진 변수를 줌\n",
        "\n",
        "# 1. 범주형 + 번주형 (문자열 합치기\n",
        "df['Planet_Cryo'] = df['HomePlanet'] + '_' + df['CryoSleep'].astype(str)\n",
        "# 2. 범주형 + 수치형 조합 (조건부 통계량)\n",
        "# 예: 각 행성별 평균 지출액 대비 본인의 지출 비중\n",
        "df['Spending_Relative_to_Planet'] = df['TotalSpending'] / (df.groupby('HomePlanet')['TotalSpending'].transform('mean') + 1)\n",
        "\n",
        "# 3. 이진형 + 이진형 (논리 연산)\n",
        "# 돈을 한 푼도 안 쓰고 동면 중인 '안전한' 승객군\n",
        "df['Safe_Passenger'] = ((df['IsSpender'] == 0) & (df['CryoSleep'] == True)).astype(int)\n"
      ],
      "metadata": {
        "id": "5DaSzqdLrzcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified K-Fold (계층적 K겹 교차 검증)\n",
        "# train과 test의 점수 차이를 줄이는 방법\n",
        "# 정답 비율을 유지하며 뭉치를 나눔\n",
        "# K개로 나누어 K번의 학습\n",
        "\n",
        "# Classification\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# optuna objective 함수 안에서\n",
        "# cv = 5 대신 cv = skf\n",
        "score = cross_val_score(pipeline, X_train, y_train, cv=skf, scoring='accuracy').mean()\n",
        "\n",
        "# Regression (계층별로 못 나누고, 무작위로 분)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "ZRYnlkHAw4Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OOF (Out-of-Fold)\n",
        "# 모델을 학습시키는 과정에서 학습 데이터를 쪼개 학습용과 검증용을 나눔\n",
        "# 5개로 나누면 1개가 검증용, 5번의 학습 진행\n",
        "\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_final),\n",
        "        ('lgbm', lgbm_final),\n",
        "        ('cat', cat_final)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5\n",
        ")\n",
        "# optuna를 진행하고 모델을 학습시킬때 StackingClassifier에서 cv=5로 사용 중\n"
      ],
      "metadata": {
        "id": "NsPGOvlKy6Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_cT6wrtzEMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 과적합 평가 (학습곡선)"
      ],
      "metadata": {
        "id": "EGxZ1YCydEcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(estimator, X, y):\n",
        "    # 훈련 데이터 양을 5단계로 나누어 실험\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=5, n_jobs=-1,\n",
        "        train_sizes=np.linspace(0.1, 1.0, 5),\n",
        "        scoring='accuracy'\n",
        "    )\n",
        "\n",
        "    # 평균과 표준편차 계산\n",
        "    train_mean = np.mean(train_scores, axis=1)\n",
        "    train_std = np.std(train_scores, axis=1)\n",
        "    test_mean = np.mean(test_scores, axis=1)\n",
        "    test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    # 그래프 그리기\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    plt.ylim(0.7, 1.02)\n",
        "    plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "\n",
        "    for i, txt in enumerate(train_mean):\n",
        "        plt.text(train_sizes[i], train_mean[i] + 0.005, f'{txt:.4f}',\n",
        "                 color='red', fontweight='bold', ha='center', va='bottom')\n",
        "\n",
        "    for i, txt in enumerate(test_mean):\n",
        "        plt.text(train_sizes[i], test_mean[i] - 0.015, f'{txt:.4f}',\n",
        "                 color='green', fontweight='bold', ha='center', va='top')\n",
        "\n",
        "    # 오차 범위 표시 (색칠)\n",
        "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "\n",
        "    plt.title(\"Learning Curve\")\n",
        "    plt.xlabel(\"Training Examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kGNdnYqBMJTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curve(final_stacking_pipeline, X_train, y_train)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ogvLzjajMUl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 변수 중요도 확인"
      ],
      "metadata": {
        "id": "jzUQlp0Moavb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_feature_importance(model, feature_names, model_name):\n",
        "    # 중요도 추출\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importances = model.feature_importances_\n",
        "    else:\n",
        "        # 가끔 모델에 따라 다른 속성명을 가질 수 있음\n",
        "        importances = model.get_feature_importances() if hasattr(model, 'get_feature_importances') else None\n",
        "\n",
        "    if importances is None:\n",
        "        print(f\"{model_name} 모델은 중요도를 지원하지 않습니다.\")\n",
        "        return\n",
        "\n",
        "    # 데이터프레임 생성\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # 시각화\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')\n",
        "    plt.title(f'Feature Importance - {model_name}')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "A0wqLmzUodZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (One-Hot Encoding 때문에 컬럼 수가 늘어났을 수 있으므로 전처리기에서 추출해야 함)\n",
        "feature_names = final_voting_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "# 앙상블 내부의 각 모델 중요도 확인\n",
        "voting_model = final_voting_pipeline.named_steps['model']\n",
        "\n",
        "\n",
        "plot_feature_importance(voting_model.named_estimators_['xgb'], feature_names, \"XGBoost\")\n",
        "\n",
        "plot_feature_importance(voting_model.named_estimators_['lgbm'], feature_names, \"LightGBM\")\n",
        "\n",
        "plot_feature_importance(voting_model.named_estimators_['cat'], feature_names, \"CatBoost\")"
      ],
      "metadata": {
        "id": "mzMCo8Q4pXIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP Summary Plot\n",
        "# 각 피처의 기여도 확인\n",
        "# 위에서 부터 중요도가 높은 순서\n",
        "# 빨간색이 값이 큰 경우\n",
        "# 오른쪽(양수)가 결과값이 양수 확률을 높임\n",
        "# 점이 많이 뭉쳐있음 -> 해당 값이 많음\n",
        "# feature_importances_보다 좋은데 느림\n",
        "\n",
        "model = pipeline.named_steps['model']\n",
        "xgb = model.named_estimators_['xgb']\n",
        "\n",
        "# 전처리기를 거친 데이터를 미리 준비해야 합니다.\n",
        "X_transformed = final_stacking_pipeline.named_steps['preprocessor'].transform(test_data)\n",
        "feature_names = final_stacking_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "# 2. Explainer 생성\n",
        "explainer = shap.TreeExplainer(xgb)\n",
        "shap_values = explainer.shap_values(X_transformed)\n",
        "\n",
        "# 3. 요약 그래프 (어떤 피처가 전체적으로 중요한가?)\n",
        "shap.summary_plot(shap_values, X_transformed, feature_names=feature_names)"
      ],
      "metadata": {
        "id": "g3ncDfI72gAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kaggle 제출하기"
      ],
      "metadata": {
        "id": "E6PPjMtIzdaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/csv/spaceship_titanic_test.csv')\n",
        "test_data = feature_engineering(test)\n",
        "test_data['TotalSpending_log'] = np.log1p(test_data['TotalSpending'])\n",
        "\n",
        "features = ['HomePlanet', 'Deck', 'Side', 'Destination', 'VIP', 'CryoSleep', 'GroupSize', 'TotalSpending_log', 'IsSpender', 'AgeGroup', 'Cabin_pos', 'Age','FamilySize', 'IsAlone']\n",
        "\n",
        "loaded_model = joblib.load('spaceship_titanic_stacking_best.pkl')\n",
        "test_preds = loaded_model.predict(test_data[features])\n",
        "test_preds = test_preds.astype(bool)\n",
        "# 8. 제출 파일 생성\n",
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test['PassengerId'],\n",
        "    'Transported': test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"제출 파일 'submission.csv'가 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "V_0FOMMCziGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 그래프"
      ],
      "metadata": {
        "id": "38NoLemqn9iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 행성별로 전송된 비율(평균)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=train, x='HomePlanet', y='Transported')\n",
        "plt.show()\n",
        "\n",
        "# 나이에 따른 전송 여부 분포\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(data=train, x='Age', hue='Transported', fill=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WJeNXuIMn__D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 행렬 다루기"
      ],
      "metadata": {
        "id": "YB1CViMhpJY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['col1', 'col2', 'col3']\n",
        "df['total'] = df[cols].sum(axis=1)\n",
        "\n",
        "df['IsSpender'] = (df['TotalSpending'] > 0).astype(int)\n",
        "\n",
        "df['IsAdult'] = df['Age'].apply(lambda x: 1 if x >= 18 else 0) # x : 승객 각각의 age"
      ],
      "metadata": {
        "id": "hETmsbJipMcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파일 사이즈 확인하기"
      ],
      "metadata": {
        "id": "vP9qPrDQ4wL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def convert_bytes(file_path, unit='bytes') :\n",
        "  size = os.path.getsize(file_path)\n",
        "  size_converted = size\n",
        "  if unit == \"KB\" :\n",
        "    size_converted = round(size/1024, 2)\n",
        "  elif unit == \"MB\" :\n",
        "    size_converted = round(size/(1024*1024), 2)\n",
        "  elif unit == \"GB\" :\n",
        "    size_converted = round(size/(1024*1024*1024), 2)\n",
        "\n",
        "  print(f\"File size: {size_converted} {unit}\")\n",
        "\n",
        "convert_bytes('/content/sample_data/mnist_test.csv', 'MB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3rw9dKR42f5",
        "outputId": "692dc114-4f96-4bfe-b0e0-f8c43d5f5570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 17.44 MB\n"
          ]
        }
      ]
    }
  ]
}