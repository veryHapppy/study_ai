{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4St79glpVyahyMEuR5RWY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veryHapppy/study_ai/blob/main/Kaggle/dog_breed_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L03d7gVrOGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b49ba4eb-87b1-4581-deba-b035240635b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.12/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m135.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (495 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.9/495.9 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.6.0 konlpy-0.6.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "!pip install plotly\n",
        "!pip install konlpy\n",
        "!pip install transformers datasets accelerate\n",
        "!pip install evaluate\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import optuna\n",
        "import optuna.visualization as vis\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from konlpy.tag import Okt\n",
        "import urllib.request\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import evaluate\n",
        "from transformers import pipeline\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import zipfile\n",
        "import json\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DogBreedDataset(Dataset):\n",
        "    def __init__(self, root_dir, csv_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "\n",
        "        # 견종 이름(문자열)을 숫자로 바꾸기 위한 딕셔너리\n",
        "        self.breeds = sorted(self.df['breed'].unique())\n",
        "        self.breed_to_idx = {breed: i for i, breed in enumerate(self.breeds)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # CSV에서 이미지 ID와 견종 가져오기\n",
        "        img_id = self.df.iloc[idx, 0]\n",
        "        breed_name = self.df.iloc[idx, 1]\n",
        "\n",
        "        # 이미지 경로 생성 (ID에 .jpg 붙이기)\n",
        "        img_path = os.path.join(self.root_dir, f\"{img_id}.jpg\")\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # 라벨을 숫자로 변환 (0~119)\n",
        "        label = self.breed_to_idx[breed_name]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(), # 컬러 이미지에선 필수!\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# 2. 테스트/검증용 (증강 제외 - 깨끗한 원본)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# 2. 데이터셋 생성 (경로를 본인의 폴더명으로 바꾸세요)\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/Dog Breed Identification/train.zip'\n",
        "extract_path = '/content/dataset/train' # 코랩 내부 경로\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(extract_path)\n",
        "\n",
        "# 1. 전체 데이터셋 생성 (아까 만든 DogCatDataset 활용)\n",
        "full_dataset = DogBreedDataset(root_dir='/content/dataset/train',csv_file='/content/drive/MyDrive/Colab Notebooks/Dog Breed Identification/labels.csv', transform=None)\n",
        "\n",
        "# 2. 비율 정하기 (예: 80%는 학습용, 20%는 검증용)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "\n",
        "# 3. 무작위로 데이터 분할\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "class ApplyTransform(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.subset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "# 이제 각각의 로더에 맞게 적용\n",
        "train_dataset = ApplyTransform(train_dataset, transform=train_transform)\n",
        "val_dataset = ApplyTransform(val_dataset, transform=test_transform)\n",
        "\n",
        "# 4. 각각의 DataLoader 생성\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False) # 검증은 섞을 필요 없음\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "W6j72uC8toTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_eval(model, train_loader, test_loader, optimizer, criterion):\n",
        "    # 3 에폭 정도만 학습해서 성능을 확인 (시간 절약)\n",
        "    for epoch in range(2):\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # 최종 검증 단계\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "def objective_step1(trial):\n",
        "    # 1. 하이퍼파라미터 제안\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
        "\n",
        "    # 2. 데이터 로더 설정\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                              shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # 3. 모델 초기화\n",
        "    model = models.resnet50(weights='DEFAULT')\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 120)\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "    for param in model.parameters(): param.requires_grad = False\n",
        "    for param in model.fc.parameters(): param.requires_grad = True\n",
        "\n",
        "    optimizer_head = optim.Adam(model.fc.parameters(), lr=1e-3)\n",
        "\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i > 50:\n",
        "            break # 약 1,600장(50배치) 정도만 학습하고 넘어감\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer_head.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_head.step()\n",
        "\n",
        "    for param in model.parameters(): param.requires_grad = True\n",
        "\n",
        "    optimizer_full = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    acc = train_and_eval(model, train_loader, val_loader, optimizer_full, criterion)\n",
        "    return acc\n",
        "\n",
        "# 1단계 실행\n",
        "study1 = optuna.create_study(direction=\"maximize\")\n",
        "study1.optimize(objective_step1, n_trials=20) # 시도횟수\n",
        "\n",
        "best_lr = study1.best_params['lr']\n",
        "best_batch_size = study1.best_params['batch_size']\n",
        "best_weight_decay = study1.best_params['weight_decay']\n",
        "print(f\"1단계 완료, 최적의 lr: {best_lr}, batch_size: {best_batch_size}, weight_decay: {best_weight_decay}\")"
      ],
      "metadata": {
        "id": "j_SWaGnuvWt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e23cdd-94eb-4ee2-e1f9-93a41c8e3635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-01-02 04:30:05,701] A new study created in memory with name: no-name-0bf9143f-8799-4f3a-819c-7da98ce816bd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 164MB/s]\n",
            "[I 2026-01-02 04:33:13,690] Trial 0 finished with value: 84.05867970660147 and parameters: {'batch_size': 32, 'lr': 2.1752200442071606e-05, 'weight_decay': 1.408523350365764e-06}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 04:36:34,300] Trial 1 finished with value: 60.440097799511 and parameters: {'batch_size': 64, 'lr': 0.0007201066770823708, 'weight_decay': 0.00022275982569817257}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 04:39:51,619] Trial 2 finished with value: 63.960880195599024 and parameters: {'batch_size': 64, 'lr': 0.0007069144461813384, 'weight_decay': 0.00021433779506590162}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 04:43:05,244] Trial 3 finished with value: 48.36185819070904 and parameters: {'batch_size': 16, 'lr': 0.000762780378271271, 'weight_decay': 6.769882095301555e-06}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 04:46:18,843] Trial 4 finished with value: 78.77750611246944 and parameters: {'batch_size': 16, 'lr': 0.00011538730068738788, 'weight_decay': 1.367203835713364e-06}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 04:49:28,333] Trial 5 finished with value: 76.67481662591688 and parameters: {'batch_size': 32, 'lr': 0.00019191442694606932, 'weight_decay': 0.0005198703689314073}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 04:52:42,970] Trial 6 finished with value: 83.71638141809291 and parameters: {'batch_size': 16, 'lr': 2.4434869311332486e-05, 'weight_decay': 8.420075976357703e-06}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 04:55:54,140] Trial 7 finished with value: 43.71638141809291 and parameters: {'batch_size': 32, 'lr': 0.0008829678898523802, 'weight_decay': 9.344701744963747e-05}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 04:59:05,262] Trial 8 finished with value: 82.64058679706602 and parameters: {'batch_size': 32, 'lr': 2.663817711924007e-05, 'weight_decay': 0.0003547305195191994}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 05:02:23,342] Trial 9 finished with value: 82.88508557457213 and parameters: {'batch_size': 64, 'lr': 0.00017690270759630476, 'weight_decay': 1.1152439369246833e-06}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 05:05:35,338] Trial 10 finished with value: 80.19559902200488 and parameters: {'batch_size': 32, 'lr': 1.3970286782260167e-05, 'weight_decay': 1.9419138957219197e-05}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 05:08:48,823] Trial 11 finished with value: 83.61858190709046 and parameters: {'batch_size': 16, 'lr': 2.9467221504677387e-05, 'weight_decay': 4.932625879913307e-06}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 05:12:02,399] Trial 12 finished with value: 83.71638141809291 and parameters: {'batch_size': 16, 'lr': 4.4312129674094276e-05, 'weight_decay': 4.854371603511434e-06}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 05:15:12,755] Trial 13 finished with value: 76.57701711491443 and parameters: {'batch_size': 32, 'lr': 1.0234646787172507e-05, 'weight_decay': 2.0304825787928178e-05}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 05:18:27,613] Trial 14 finished with value: 82.34718826405867 and parameters: {'batch_size': 16, 'lr': 5.531242959234162e-05, 'weight_decay': 2.3921339864917757e-06}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 05:21:38,947] Trial 15 finished with value: 83.32518337408312 and parameters: {'batch_size': 32, 'lr': 1.8717193935902684e-05, 'weight_decay': 5.118479421868884e-05}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 05:24:52,474] Trial 16 finished with value: 82.3960880195599 and parameters: {'batch_size': 16, 'lr': 5.884108686750282e-05, 'weight_decay': 8.48616953641079e-06}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 05:28:02,540] Trial 17 finished with value: 83.71638141809291 and parameters: {'batch_size': 32, 'lr': 2.4095970051682043e-05, 'weight_decay': 2.5482267608783593e-06}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 05:31:17,491] Trial 18 finished with value: 82.20048899755501 and parameters: {'batch_size': 16, 'lr': 8.795316473665695e-05, 'weight_decay': 1.3156911164988623e-05}. Best is trial 0 with value: 84.05867970660147.\n",
            "[I 2026-01-02 05:34:37,602] Trial 19 finished with value: 84.44987775061125 and parameters: {'batch_size': 64, 'lr': 4.0122966671348226e-05, 'weight_decay': 2.8290255515133917e-06}. Best is trial 19 with value: 84.44987775061125.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1단계 완료, 최적의 lr: 4.0122966671348226e-05, batch_size: 64, weight_decay: 2.8290255515133917e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/Dog Breed Identification/best_params_step1.json', 'w') as f:\n",
        "    json.dump(study1.best_params, f)"
      ],
      "metadata": {
        "id": "4Q2j2K1WvpSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 그 레시피대로 '진짜 최종 모델'을 생성합니다.\n",
        "final_model = models.resnet50(weights='DEFAULT')\n",
        "num_ftrs = final_model.fc.in_features\n",
        "final_model.fc = nn.Linear(num_ftrs, 120) # 120\n",
        "final_model = final_model.to(device)\n",
        "\n",
        "history = {'train_loss': [], 'val_acc': []}\n",
        "\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataset = ApplyTransform(train_dataset, transform=train_transform)\n",
        "val_dataset = ApplyTransform(val_dataset, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=best_batch_size,\n",
        "                          shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "for param in final_model.parameters(): param.requires_grad = False\n",
        "for param in final_model.fc.parameters(): param.requires_grad = True\n",
        "\n",
        "optimizer = optim.Adam(final_model.fc.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "print(\"Starting Phase 1...\")\n",
        "for epoch in range(5):\n",
        "    final_model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = final_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Phase 1 - Epoch [{epoch+1}/5] Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "for param in final_model.parameters(): param.requires_grad = True\n",
        "\n",
        "optimizer = optim.Adam(final_model.parameters(), lr=best_lr, weight_decay=best_weight_decay)\n",
        "# 학습률 스케줄러 추가 (성능 향상 정체 시 0.1배 감소)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "    final_model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = final_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # 에폭마다 검증 (테스트셋 활용)\n",
        "    final_model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = final_model(images)\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            correct += (pred == labels).sum().item()\n",
        "    acc = 100 * correct / len(val_dataset)\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    scheduler.step(acc)\n",
        "    history['train_loss'].append(avg_loss)\n",
        "    history['val_acc'].append(acc)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}, Acc: {acc:.2f}%\")\n",
        "\n",
        "print(\"최종 모델 학습 완료\")"
      ],
      "metadata": {
        "id": "Bnj_Mb5IvqRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ee181d-2f09-4594-8557-ecae186c5ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Phase 1...\n",
            "Phase 1 - Epoch [1/5] Loss: 3.3058\n",
            "Phase 1 - Epoch [2/5] Loss: 1.7367\n",
            "Phase 1 - Epoch [3/5] Loss: 1.3674\n",
            "Phase 1 - Epoch [4/5] Loss: 1.2317\n",
            "Phase 1 - Epoch [5/5] Loss: 1.1601\n",
            "Epoch [1/30] - Loss: 1.0696, Acc: 87.24%\n",
            "Epoch [2/30] - Loss: 0.9972, Acc: 87.53%\n",
            "Epoch [3/30] - Loss: 0.9601, Acc: 87.78%\n",
            "Epoch [4/30] - Loss: 0.9330, Acc: 87.58%\n",
            "Epoch [5/30] - Loss: 0.9131, Acc: 87.29%\n",
            "Epoch [6/30] - Loss: 0.8973, Acc: 87.09%\n",
            "Epoch [7/30] - Loss: 0.8843, Acc: 87.19%\n",
            "Epoch [8/30] - Loss: 0.8744, Acc: 87.48%\n",
            "Epoch [9/30] - Loss: 0.8703, Acc: 87.33%\n",
            "Epoch [10/30] - Loss: 0.8706, Acc: 87.58%\n",
            "Epoch [11/30] - Loss: 0.8673, Acc: 87.43%\n",
            "Epoch [12/30] - Loss: 0.8670, Acc: 87.48%\n",
            "Epoch [13/30] - Loss: 0.8660, Acc: 87.53%\n",
            "Epoch [14/30] - Loss: 0.8654, Acc: 87.48%\n",
            "Epoch [15/30] - Loss: 0.8654, Acc: 87.09%\n",
            "Epoch [16/30] - Loss: 0.8659, Acc: 87.14%\n",
            "Epoch [17/30] - Loss: 0.8657, Acc: 87.43%\n",
            "Epoch [18/30] - Loss: 0.8667, Acc: 87.48%\n",
            "Epoch [19/30] - Loss: 0.8667, Acc: 87.29%\n",
            "Epoch [20/30] - Loss: 0.8659, Acc: 87.19%\n",
            "Epoch [21/30] - Loss: 0.8655, Acc: 87.43%\n",
            "Epoch [22/30] - Loss: 0.8650, Acc: 87.24%\n",
            "Epoch [23/30] - Loss: 0.8657, Acc: 87.33%\n",
            "Epoch [24/30] - Loss: 0.8663, Acc: 87.43%\n",
            "Epoch [25/30] - Loss: 0.8652, Acc: 87.58%\n",
            "Epoch [26/30] - Loss: 0.8662, Acc: 87.24%\n",
            "Epoch [27/30] - Loss: 0.8648, Acc: 87.04%\n",
            "Epoch [28/30] - Loss: 0.8644, Acc: 87.24%\n",
            "Epoch [29/30] - Loss: 0.8651, Acc: 87.19%\n",
            "Epoch [30/30] - Loss: 0.8650, Acc: 87.48%\n",
            "최종 모델 학습 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/Colab Notebooks/Dog Breed Identification'\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "# 모델 저장 (가장 성능이 좋았을 때 실행)\n",
        "torch.save(final_model.state_dict(), f\"{save_path}/final_model.pth\")"
      ],
      "metadata": {
        "id": "Mf0Ddw2zvw9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PlantTestDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        # test 폴더 내의 모든 이미지 파일 목록 (정렬하여 순서 보장)\n",
        "        self.file_list = sorted([f for f in os.listdir(root_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.file_list[idx]\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name # 이미지와 파일명을 함께 반환\n",
        "\n",
        "def generate_submission(model, test_loader, class_names, save_path):\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_files = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, file_names in test_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            # 1. 각 클래스별 확률값 계산 (Softmax)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "            # CPU로 옮기고 리스트에 저장\n",
        "            all_probs.append(probs.cpu().numpy())\n",
        "\n",
        "            # 2. 파일명 처리 (확장자 제거)\n",
        "            for f in file_names:\n",
        "                all_files.append(f.replace('.jpg', ''))\n",
        "\n",
        "    # 3. 모든 배치의 확률을 하나로 합침\n",
        "    all_probs = np.vstack(all_probs)\n",
        "\n",
        "    # 4. 데이터프레임 생성 (id 컬럼 + 120개 품종 컬럼)\n",
        "    submission = pd.DataFrame(all_probs, columns=class_names)\n",
        "    submission.insert(0, 'id', all_files) # 맨 앞에 id 컬럼 삽입\n",
        "\n",
        "    submission.to_csv(save_path, index=False)\n",
        "    print(f\"제출 파일(확률 포함)이 저장되었습니다: {save_path}\")\n",
        "\n",
        "# --- 실행 부분 ---\n",
        "\n",
        "# 1. 테스트 데이터 압축 해제 (이미 하셨다면 생략)\n",
        "test_zip_path = '/content/drive/MyDrive/Colab Notebooks/Dog Breed Identification/test.zip'\n",
        "with zipfile.ZipFile(test_zip_path, 'r') as z:\n",
        "    z.extractall('/content/dataset/test_data')\n",
        "\n",
        "# 2. 테스트 로더 설정 (test_transform 사용)\n",
        "test_dataset = PlantTestDataset(root_dir='/content/dataset/test_data', transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 3. 클래스 이름 목록 가져오기 (ImageFolder에서 썼던 순서 그대로)\n",
        "class_names = full_dataset.breeds\n",
        "\n",
        "# 4. 제출 파일 생성\n",
        "generate_submission(final_model, test_loader, class_names, '/content/drive/MyDrive/Colab Notebooks/Dog Breed Identification/submission.csv')"
      ],
      "metadata": {
        "id": "pXv2f_Uev1zx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6cc81e3-1121-4e8e-aaef-a96e28356a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "제출 파일(확률 포함)이 저장되었습니다: /content/drive/MyDrive/Colab Notebooks/Dog Breed Identification/submission.csv\n"
          ]
        }
      ]
    }
  ]
}